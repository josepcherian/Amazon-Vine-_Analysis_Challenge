{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"16.6.1_Notes.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNWMhuPnc6qItcSPHTe+JJC"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JaK8yAem009h","executionInfo":{"status":"ok","timestamp":1612656662926,"user_tz":360,"elapsed":23260,"user":{"displayName":"Julie Pyle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwK-ZsQZg06vAJJaL8rk7twbJ4h5WXmW603dBa9w=s64","userId":"01424704684608021156"}},"outputId":"3074fc57-5aa0-4bbf-951a-eaee7df5aba9"},"source":["# Module 16.6.1\r\n","import os\r\n","# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\r\n","# For example:\r\n","# spark_version = 'spark-3.0.1'\r\n","spark_version = 'spark-3.0.1'\r\n","os.environ['SPARK_VERSION']=spark_version\r\n","\r\n","# Install Spark and Java\r\n","!apt-get update\r\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\r\n","!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\r\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\r\n","!pip install -q findspark\r\n","\r\n","# Set Environment Variables\r\n","import os\r\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\r\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\r\n","\r\n","# Start a SparkSession\r\n","import findspark\r\n","findspark.init()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","\r0% [Connecting to archive.ubuntu.com] [1 InRelease 14.2 kB/88.7 kB 16%] [Connec\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Connected to cloud.r-pro\r0% [1 InRelease gpgv 88.7 kB] [Connecting to archive.ubuntu.com (91.189.88.142)\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","\r0% [1 InRelease gpgv 88.7 kB] [Connecting to archive.ubuntu.com (91.189.88.142)\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","\r0% [1 InRelease gpgv 88.7 kB] [Connecting to archive.ubuntu.com (91.189.88.142)\r0% [1 InRelease gpgv 88.7 kB] [Connecting to archive.ubuntu.com (91.189.88.142)\r                                                                               \rGet:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [4 InRelease 14.2 kB/15.9 k\r                                                                               \rIgn:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [4 InRelease 14.2 kB/15.9 k\r                                                                               \rGet:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n","\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [4 InRelease 14.2 kB/15.9 k\r                                                                               \rHit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n","Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:13 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [44.8 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Ign:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n","Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [552 kB]\n","Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,725 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,157 kB]\n","Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [883 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,352 kB]\n","Fetched 7,987 kB in 3s (2,668 kB/s)\n","Reading package lists... Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DVwAGBTu145D"},"source":["# Start Spark session\r\n","from pyspark.sql import SparkSession\r\n","spark = SparkSession.builder.appName(\"Tokens\").getOrCreate()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RhtS116A147d"},"source":["from pyspark.ml.feature import Tokenizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9VRCG6eK14-N","executionInfo":{"status":"ok","timestamp":1612657093540,"user_tz":360,"elapsed":3950,"user":{"displayName":"Julie Pyle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwK-ZsQZg06vAJJaL8rk7twbJ4h5WXmW603dBa9w=s64","userId":"01424704684608021156"}},"outputId":"d8d5541c-b762-4e81-c06b-8a8622a1a071"},"source":["# Create sample Dataframe\r\n","dataframe = spark.createDataFrame([\r\n","                                   (0, \"Spark is great\"),\r\n","                                   (1,\"We are learning Spark\"),\r\n","                                   (2, \"Spark is better than hadoop no doubt\")\r\n","],[\"id\",\"sentence\"])\r\n","dataframe.show()\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+---+--------------------+\n","| id|            sentence|\n","+---+--------------------+\n","|  0|      Spark is great|\n","|  1|We are learning S...|\n","|  2|Spark is better t...|\n","+---+--------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W2lVAlcJ15Am","executionInfo":{"status":"ok","timestamp":1612657101714,"user_tz":360,"elapsed":193,"user":{"displayName":"Julie Pyle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwK-ZsQZg06vAJJaL8rk7twbJ4h5WXmW603dBa9w=s64","userId":"01424704684608021156"}},"outputId":"ea299d38-563b-404e-9fd7-43ca61ba1376"},"source":["# Tokenize sentences\r\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\r\n","tokenizer"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Tokenizer_51f85a69295d"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pdDJm3yK2pJ6","executionInfo":{"status":"ok","timestamp":1612657182007,"user_tz":360,"elapsed":1441,"user":{"displayName":"Julie Pyle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwK-ZsQZg06vAJJaL8rk7twbJ4h5WXmW603dBa9w=s64","userId":"01424704684608021156"}},"outputId":"b71ebedb-8e1e-43e8-bf51-e72239515f0e"},"source":["# Transform and show DataFrame\r\n","tokenized_df = tokenizer.transform(dataframe)\r\n","tokenized_df.show(truncate=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+---+------------------------------------+--------------------------------------------+\n","|id |sentence                            |words                                       |\n","+---+------------------------------------+--------------------------------------------+\n","|0  |Spark is great                      |[spark, is, great]                          |\n","|1  |We are learning Spark               |[we, are, learning, spark]                  |\n","|2  |Spark is better than hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|\n","+---+------------------------------------+--------------------------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MXZib6Wz2pM6"},"source":["# Create a function to return the length of a list\r\n","def word_list_length(word_list):\r\n","    return len(word_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T-LaWgyt2pUD"},"source":["from pyspark.sql.functions import col, udf\r\n","from pyspark.sql.types import IntegerType"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CTFDu7UT2pW6"},"source":["# Create a user defined function\r\n","count_tokens = udf(word_list_length, IntegerType())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aSogGw_U2pZq","executionInfo":{"status":"ok","timestamp":1612657501902,"user_tz":360,"elapsed":1529,"user":{"displayName":"Julie Pyle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwK-ZsQZg06vAJJaL8rk7twbJ4h5WXmW603dBa9w=s64","userId":"01424704684608021156"}},"outputId":"46ce65e7-8973-446c-92d8-706729ce1656"},"source":["# Create our Tokenizer\r\n","tokenizer = Tokenizer(inputCol=\"sentence\",outputCol=\"words\")\r\n","\r\n","# Transform and show DataFrame\r\n","tokenized_df = tokenizer.transform(dataframe)\r\n","\r\n","# Select the needed columns and don't truncate results\r\n","tokenized_df.withColumn(\"tokens\",count_tokens(col(\"words\"))).show(truncate=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+---+------------------------------------+--------------------------------------------+------+\n","|id |sentence                            |words                                       |tokens|\n","+---+------------------------------------+--------------------------------------------+------+\n","|0  |Spark is great                      |[spark, is, great]                          |3     |\n","|1  |We are learning Spark               |[we, are, learning, spark]                  |4     |\n","|2  |Spark is better than hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|7     |\n","+---+------------------------------------+--------------------------------------------+------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TClfatJc15Cr"},"source":[""],"execution_count":null,"outputs":[]}]}