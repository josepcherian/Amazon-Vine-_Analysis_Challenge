{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"16.6.2_mod.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPbxoqg2SW+RyAkJXMlH5Jn"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Efhqnre45gSX","executionInfo":{"status":"ok","timestamp":1612674745335,"user_tz":360,"elapsed":20780,"user":{"displayName":"Julie Pyle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwK-ZsQZg06vAJJaL8rk7twbJ4h5WXmW603dBa9w=s64","userId":"01424704684608021156"}},"outputId":"415da156-8845-4920-c045-e7d6c8da95b7"},"source":["# Module 16.6.2 Stop Words\r\n","import os\r\n","# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\r\n","# For example:\r\n","# spark_version = 'spark-3.0.1'\r\n","spark_version = 'spark-3.0.1'\r\n","os.environ['SPARK_VERSION']=spark_version\r\n","\r\n","# Install Spark and Java\r\n","!apt-get update\r\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\r\n","!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\r\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\r\n","!pip install -q findspark\r\n","\r\n","# Set Environment Variables\r\n","import os\r\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\r\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\r\n","\r\n","# Start a SparkSession\r\n","import findspark\r\n","findspark.init()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n","\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connecting to cloud.r-pr\r0% [1 InRelease gpgv 88.7 kB] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connected to cloud.r-proje\r                                                                               \rHit:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","\r                                                                               \r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers]\r                                                                         \rHit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","Hit:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n","Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Reading package lists... Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AdLJfyc-5w0I"},"source":["# Start Spark session\r\n","from pyspark.sql import SparkSession\r\n","spark = SparkSession.builder.appName(\"StopWords\").getOrCreate()\r\n","# Skill Drill 16.6.2 added to make work\r\n","from pyspark.sql.functions import col, udf\r\n","from pyspark.sql.types import IntegerType\r\n","from pyspark.ml.feature import Tokenizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bukGS7ew5w3X"},"source":["# Create DataFrame\r\n","sentenceData = spark.createDataFrame([\r\n","                                      (0, [\"Big\",\"data\",\"is\",\"super\",\"powerful\"]),\r\n","                                      (1,[\"This\",\"is\",\"going\",\"to\",\"be\",\"epic\"])\r\n","],[\"id\",\"raw\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sahBXQeA-_uc"},"source":["# Import stop words library\r\n","from pyspark.ml.feature import StopWordsRemover"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wbua6Kgq-_xO"},"source":["# Run the Remover\r\n","remover = StopWordsRemover(inputCol=\"raw\", outputCol=\"filtered\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EJvFN0Rk-_z0","executionInfo":{"status":"ok","timestamp":1612674745834,"user_tz":360,"elapsed":21246,"user":{"displayName":"Julie Pyle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwK-ZsQZg06vAJJaL8rk7twbJ4h5WXmW603dBa9w=s64","userId":"01424704684608021156"}},"outputId":"bb2e30ec-d9ed-46a3-e1e2-e2bdbc249196"},"source":["#Tansform and show data\r\n","remover.transform(sentenceData).show(truncate=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+---+--------------------------------+----------------------------+\n","|id |raw                             |filtered                    |\n","+---+--------------------------------+----------------------------+\n","|0  |[Big, data, is, super, powerful]|[Big, data, super, powerful]|\n","|1  |[This, is, going, to, be, epic] |[going, epic]               |\n","+---+--------------------------------+----------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GsCaz60T_QxM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612674746205,"user_tz":360,"elapsed":21611,"user":{"displayName":"Julie Pyle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwK-ZsQZg06vAJJaL8rk7twbJ4h5WXmW603dBa9w=s64","userId":"01424704684608021156"}},"outputId":"4076a6ee-6dde-4572-dcff-0286d959fca4"},"source":["# Skill Drill 16.6.2 Combine a tokenizer and a stopword remover on a datafram not broken out\r\n","# Create sample Dataframe\r\n","dataframe_mod = spark.createDataFrame([\r\n","                                   (0, \"Spark is great\"),\r\n","                                   (1, \"We are learning Spark\"),\r\n","                                   (2, \"Spark is better than hadoop no doubt\"),\r\n","                                   (3, \"Adding a line for skill drill practice\")\r\n","],[\"id\",\"sentence\"])\r\n","dataframe_mod.show(truncate=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+---+--------------------------------------+\n","|id |sentence                              |\n","+---+--------------------------------------+\n","|0  |Spark is great                        |\n","|1  |We are learning Spark                 |\n","|2  |Spark is better than hadoop no doubt  |\n","|3  |Adding a line for skill drill practice|\n","+---+--------------------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4AzQrrcf3so4"},"source":["# Skill Drill 16.6.2 Combine a tokenizer and a stopword remover on a datafram not broken out\r\n","# Create a function to return the length of a list\r\n","def word_list_length(word_list):\r\n","    return len(word_list)\r\n","# Create a user defined function   \r\n","count_tokens = udf(word_list_length, IntegerType())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aSogGw_U2pZq","executionInfo":{"status":"ok","timestamp":1612674790264,"user_tz":360,"elapsed":1106,"user":{"displayName":"Julie Pyle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwK-ZsQZg06vAJJaL8rk7twbJ4h5WXmW603dBa9w=s64","userId":"01424704684608021156"}},"outputId":"5dfbfb2c-5983-46ad-b8dc-335da504bc96"},"source":["# Skill Drill 16.6.2 Combine a tokenizer and a stopword remover on a datafram not broken out\r\n","# Create our Tokenizer\r\n","tokenizer = Tokenizer(inputCol=\"sentence\",outputCol=\"words\")\r\n","\r\n","# Transform and show DataFrame\r\n","dataframe_mod = tokenizer.transform(dataframe_mod)\r\n","\r\n","# Select the needed columns and don't truncate results\r\n","dataframe_mod.withColumn(\"tokens\",count_tokens(col(\"words\"))).show(truncate=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+---+--------------------------------------+----------------------------------------------+------+\n","|id |sentence                              |words                                         |tokens|\n","+---+--------------------------------------+----------------------------------------------+------+\n","|0  |Spark is great                        |[spark, is, great]                            |3     |\n","|1  |We are learning Spark                 |[we, are, learning, spark]                    |4     |\n","|2  |Spark is better than hadoop no doubt  |[spark, is, better, than, hadoop, no, doubt]  |7     |\n","|3  |Adding a line for skill drill practice|[adding, a, line, for, skill, drill, practice]|7     |\n","+---+--------------------------------------+----------------------------------------------+------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a2u-Xm0o2GS-"},"source":["# Skill Drill 16.6.2 Combine a tokenizer and a stopword remover on a datafram not broken out\r\n","# Run the Remover\r\n","remover_mod = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FPcFVfBx2GbD","executionInfo":{"status":"ok","timestamp":1612675046879,"user_tz":360,"elapsed":693,"user":{"displayName":"Julie Pyle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwK-ZsQZg06vAJJaL8rk7twbJ4h5WXmW603dBa9w=s64","userId":"01424704684608021156"}},"outputId":"e2572908-63bd-4b47-b9b9-8ad7bda6bbb3"},"source":["# Skill Drill 16.6.2 Combine a tokenizer and a stopword remover on a datafram not broken out\r\n","#Tansform and show data\r\n","remover_mod.transform(dataframe_mod).show(truncate=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+---+--------------------------------------+----------------------------------------------+--------------------------------------+\n","|id |sentence                              |words                                         |filtered                              |\n","+---+--------------------------------------+----------------------------------------------+--------------------------------------+\n","|0  |Spark is great                        |[spark, is, great]                            |[spark, great]                        |\n","|1  |We are learning Spark                 |[we, are, learning, spark]                    |[learning, spark]                     |\n","|2  |Spark is better than hadoop no doubt  |[spark, is, better, than, hadoop, no, doubt]  |[spark, better, hadoop, doubt]        |\n","|3  |Adding a line for skill drill practice|[adding, a, line, for, skill, drill, practice]|[adding, line, skill, drill, practice]|\n","+---+--------------------------------------+----------------------------------------------+--------------------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oimdLmzl2GhR"},"source":[""],"execution_count":null,"outputs":[]}]}